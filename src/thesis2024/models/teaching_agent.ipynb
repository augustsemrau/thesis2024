{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "# Langchain imports\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, Tool, create_react_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Tool imports\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain.utilities import DuckDuckGoSearchAPIWrapper\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "# Local imports\n",
    "from thesis2024.models.coding_agent import CodingMultiAgent\n",
    "\n",
    "\n",
    "def init_llm_langsmith(llm_key = 3, temp = 0.5):\n",
    "    \"\"\"Initialize the LLM model and LangSmith tracing.\"\"\"\n",
    "    # Set environment variables\n",
    "    def _set_if_undefined(var: str):\n",
    "        if not os.environ.get(var):\n",
    "            os.environ[var] = getpass(f\"Please provide your {var}\")\n",
    "    _set_if_undefined(\"OPENAI_API_KEY\")\n",
    "    _set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "    # Add tracing in LangSmith.\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    if llm_key == 3:\n",
    "        llm_ver = \"gpt-3.5-turbo-0125\"\n",
    "        os.environ[\"LANGCHAIN_PROJECT\"] = \"GPT-3.5 Teaching Agent System TEST 1\"\n",
    "    elif llm_key == 4:\n",
    "        llm_ver = \"gpt-4-0125-preview\"\n",
    "        os.environ[\"LANGCHAIN_PROJECT\"] = \"GPT-4 Teaching Agent System TEST 1\"\n",
    "\n",
    "    llm_model = ChatOpenAI(model_name=llm_ver, temperature=temp)\n",
    "    return llm_model\n",
    "\n",
    "llm_model = init_llm_langsmith(llm_key=3, temp=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Search tool.\"\"\"\n",
    "search = DuckDuckGoSearchAPIWrapper()\n",
    "search_tool = Tool(name=\"Current Search\",\n",
    "                   func=search.run,\n",
    "                   description=\"Useful when you need to answer questions about nouns, current events or the current state of the world.\"\n",
    "                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Coding multi-agent tool.\"\"\"\n",
    "coding_subgraph_class = CodingMultiAgent(llm_model=llm_model)\n",
    "coding_graph = coding_subgraph_class.instanciate_graph()\n",
    "\n",
    "\n",
    "def coding_function(query: str):\n",
    "\n",
    "    output = coding_graph.invoke({\"messages\": [HumanMessage(content=query)]},\n",
    "                        {\"recursion_limit\": 100})\n",
    "    return output[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "# Placeholder gradient descent code\n",
    "def coding_function(query: str):\n",
    "    \"\"\"Placeholding for coding tool.\"\"\"\n",
    "    return \"\"\"This is a coding example.\n",
    "\n",
    "    ```python\n",
    "    def gradient_descent(x, y, learning_rate=0.01, epochs=100):\n",
    "        m = 0\n",
    "        b = 0\n",
    "        n = len(x)\n",
    "        for _ in range(epochs):\n",
    "            y_pred = m * x + b\n",
    "            m_gradient = (-2/n) * sum(x * (y - y_pred))\n",
    "            b_gradient = (-2/n) * sum(y - y_pred)\n",
    "            m -= learning_rate * m_gradient\n",
    "            b -= learning_rate * b_gradient\n",
    "        return m, b\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "coding_tool = StructuredTool.from_function(\n",
    "                            func=coding_function,\n",
    "                            name=\"Coding Tool\",\n",
    "                            description=\"Useful when you need to answer questions using a coded example.\"\n",
    "                            )\n",
    "\n",
    "tools = [search_tool, coding_tool]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Teaching Agents System with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'chat_history', 'input', 'tool_names', 'tools'] partial_variables={'system_message': 'You will interact with a student who has no prior knowledge of the subject.', 'course_name': 'Introduction to Computer Science', 'subject_name': 'Gradient Descent'} template='Teaching Assistant is a large language model trained by OpenAI.\\n\\nTeaching Assistant is designed to be able to assist with teaching related tasks, from answering simple questions to providing in-depth explanations and discussions on STEM topics. \\nAs a language model, Teaching Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nTeaching Assistant is constantly learning and improving, and its capabilities are constantly evolving. \\nIt is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. \\nAdditionally, Teaching Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Teaching Assistant is a powerful tool that can help students with understanding STEM topics. \\nWhether you need help with a specific question or just want to have a conversation about a particular topic, Teaching Assistant is here to assist.\\n\\n{system_message}\\n\\nTeaching Assistant is assisting in the course {course_name}.\\nIn this particular conversation, the student needs help with learning the subject {subject_name}\\n\\n\\nTOOLS:\\n------\\n\\nTeaching assistant has access to the following tools:\\n\\n{tools}\\n\\nIf you need to use a tool, your final answer MUST be identical to the output of the tool, and you can only call a tool once.\\nIf you use a tool, you MUST use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: an explanation for the task that the tool should solve\\nObservation: the result of the action\\nFinal Answer: [Observation]\\n```\\n\\n\\nIf you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nFinal Answer: [your response here]\\n```\\n\\nBegin!\\n\\nPrevious conversation history:\\n{chat_history}\\n\\nNew input: {input}\\n{agent_scratchpad}'\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "SYSTEM_MESSAGE = \"\"\"You will interact with a student who has no prior knowledge of the subject.\"\"\"\n",
    "COURSE = \"\"\"Introduction to Computer Science\"\"\"\n",
    "SUBJECT = \"\"\"Gradient Descent\"\"\"\n",
    "\n",
    "prompt_hub_template = hub.pull(\"augustsemrau/react-teaching-chat\").template\n",
    "prompt_template = PromptTemplate.from_template(template=prompt_hub_template)\n",
    "prompt = prompt_template.partial(system_message=SYSTEM_MESSAGE, course_name=COURSE, subject_name=SUBJECT)\n",
    "print(prompt)\n",
    "\n",
    "agent = create_react_agent(llm=llm_model, tools=tools, prompt=prompt, output_parser=None)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True, handle_parsing_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "Final Answer: Hello August! How can I assist you today with learning about Gradient Descent in Computer Science?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello August! How can I assist you today with learning about Gradient Descent in Computer Science?'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Hello I am August?\",})[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Current Search\n",
      "Action Input: Look up information about Gradient Descent in Computer Science\u001b[0m\u001b[36;1m\u001b[1;3mFinally, gradient descent might never find the global minimum. The algorithm is not able to distinguish between a local and global minimum. As it descent in search of the local minimum, once it converges it will then stop. The local minimum will corner the algorithm in the local minimum own valley preventing the step to be large enough to exit. 5. Optimization. 1. Introduction. In this tutorial, we'll try to build a general intuition behind the gradient descent algorithm. By understanding the mathematics behind gradient descent, we'll understand why it works for problems like linear regression. More importantly, we'll see why it's effective compared to other ways to solve such ... In summary, gradient descent is stable, capable of handling large datasets and numerous parameters, making it a superior choice for our learning purposes. In the gradient descent formula ðœƒ = ðœƒ â€” ðœ‚â‹…âˆ‡ðœƒð½(ðœƒ), we use the learning rate (ðœ‚) multiplied by the gradient (âˆ‡ðœƒð½(ðœƒ)) to update each parameter. Gradient Descent is a fundamental and transformative optimization algorithm that lies at the heart of numerous scientific and engineering applications. Its ability to navigate complex, high ... Let's try using the same learning rate and number of iterations that we used for batch gradient descent. 1ï¸âƒ£ Let's set learning_rate=0.01 with 1000 iterations and plot the loss function. # Find optimal parameters using SGD. m, b, params, loss = stochastic_gradient_descent(x, y, learning_rate=0.01,\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: Gradient Descent is a fundamental optimization algorithm used in various scientific and engineering applications. It works by iteratively updating parameters based on the gradient of the loss function to find the optimal values. However, it may not always find the global minimum and can get stuck in local minima.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Can you look up what it is about?',\n",
       " 'chat_history': [HumanMessage(content='Hello I am August?'),\n",
       "  AIMessage(content='Hello August! How can I assist you today with learning about Gradient Descent in Computer Science?'),\n",
       "  HumanMessage(content='Can you look up what it is about?'),\n",
       "  AIMessage(content='Gradient Descent is a fundamental optimization algorithm used in various scientific and engineering applications. It works by iteratively updating parameters based on the gradient of the loss function to find the optimal values. However, it may not always find the global minimum and can get stuck in local minima.')],\n",
       " 'output': 'Gradient Descent is a fundamental optimization algorithm used in various scientific and engineering applications. It works by iteratively updating parameters based on the gradient of the loss function to find the optimal values. However, it may not always find the global minimum and can get stuck in local minima.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Can you look up what it is about?\",})#[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "Final Answer: Gradient Descent is an optimization algorithm used in machine learning to minimize the error of a model by adjusting its parameters iteratively. It works by calculating the gradient of the loss function with respect to the model's parameters and updating the parameters in the opposite direction of the gradient to reach the minimum error. In simpler terms, it's like trying to find the lowest point in a valley by taking small steps downhill.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Gradient Descent is an optimization algorithm used in machine learning to minimize the error of a model by adjusting its parameters iteratively. It works by calculating the gradient of the loss function with respect to the model's parameters and updating the parameters in the opposite direction of the gradient to reach the minimum error. In simpler terms, it's like trying to find the lowest point in a valley by taking small steps downhill.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Can you give a deep explanation of the subject?\",})[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "Final Answer: Sure! An analogy for gradient descent is like trying to find the lowest point in a hilly terrain by taking small steps downhill in the steepest direction. You keep adjusting your steps until you reach the lowest point.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Can you give an analogy for that?',\n",
       " 'chat_history': [HumanMessage(content='Hello I am August?'),\n",
       "  AIMessage(content='Hello August! How can I assist you today?'),\n",
       "  HumanMessage(content='I want to know what gradient descent is'),\n",
       "  AIMessage(content='Gradient descent is an optimization algorithm used in machine learning to minimize the loss function by iteratively moving in the direction of the steepest descent of the loss function. It is commonly used in training machine learning models, such as neural networks, to find the optimal parameters that minimize the error between the predicted output and the actual output.'),\n",
       "  HumanMessage(content='Please code an example of gradient descent for me.'),\n",
       "  AIMessage(content='Here is an example of gradient descent algorithm:\\n\\n```python\\n# Initialize variables\\nx = 5\\ny = 10\\n\\n# Calculate the sum\\nz = x + y\\n\\n# Print the result\\nprint(z)\\n```'),\n",
       "  HumanMessage(content='Can you give an analogy for that?'),\n",
       "  AIMessage(content='Sure! An analogy for gradient descent is like trying to find the lowest point in a hilly terrain by taking small steps downhill in the steepest direction. You keep adjusting your steps until you reach the lowest point.')],\n",
       " 'output': 'Sure! An analogy for gradient descent is like trying to find the lowest point in a hilly terrain by taking small steps downhill in the steepest direction. You keep adjusting your steps until you reach the lowest point.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Can you give an analogy for that?\",})#[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Coding Tool\n",
      "Action Input: Please code an example of gradient descent for me.\u001b[0m\u001b[33;1m\u001b[1;3mThis is a coding example.\n",
      "\n",
      "    ```python\n",
      "    def gradient_descent(x, y, learning_rate=0.01, epochs=100):\n",
      "        m = 0\n",
      "        b = 0\n",
      "        n = len(x)\n",
      "        for _ in range(epochs):\n",
      "            y_pred = m * x + b\n",
      "            m_gradient = (-2/n) * sum(x * (y - y_pred))\n",
      "            b_gradient = (-2/n) * sum(y - y_pred)\n",
      "            m -= learning_rate * m_gradient\n",
      "            b -= learning_rate * b_gradient\n",
      "        return m, b\n",
      "    ```\n",
      "    \u001b[0m\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "Final Answer: Here is an example of gradient descent in Python:\n",
      "\n",
      "```python\n",
      "def gradient_descent(x, y, learning_rate=0.01, epochs=100):\n",
      "    m = 0\n",
      "    b = 0\n",
      "    n = len(x)\n",
      "    for _ in range(epochs):\n",
      "        y_pred = m * x + b\n",
      "        m_gradient = (-2/n) * sum(x * (y - y_pred))\n",
      "        b_gradient = (-2/n) * sum(y - y_pred)\n",
      "        m -= learning_rate * m_gradient\n",
      "        b -= learning_rate * b_gradient\n",
      "    return m, b\n",
      "```\n",
      "\n",
      "This code snippet demonstrates a simple implementation of gradient descent to find the optimal values of `m` and `b` in a linear regression model.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Please code an example of gradient descent for me.',\n",
       " 'chat_history': [HumanMessage(content='Hello I am August?'),\n",
       "  AIMessage(content='Hello August! How can I assist you today with learning about Gradient Descent in Computer Science?'),\n",
       "  HumanMessage(content='What is it about?'),\n",
       "  AIMessage(content=\"Gradient Descent is an optimization algorithm commonly used in machine learning and deep learning to minimize the error of a model by adjusting its parameters iteratively. It works by calculating the gradient of the loss function with respect to the model's parameters and updating the parameters in the opposite direction of the gradient to reach the minimum error.\"),\n",
       "  HumanMessage(content='Can you give a deep explanation of the subject?'),\n",
       "  AIMessage(content=\"Gradient Descent is an optimization algorithm used in machine learning to minimize the error of a model by adjusting its parameters iteratively. It works by calculating the gradient of the loss function with respect to the model's parameters and updating the parameters in the opposite direction of the gradient to reach the minimum error. In simpler terms, it's like trying to find the lowest point in a valley by taking small steps downhill.\"),\n",
       "  HumanMessage(content='Please code an example of gradient descent for me.'),\n",
       "  AIMessage(content='Here is an example of gradient descent in Python:\\n\\n```python\\ndef gradient_descent(x, y, learning_rate=0.01, epochs=100):\\n    m = 0\\n    b = 0\\n    n = len(x)\\n    for _ in range(epochs):\\n        y_pred = m * x + b\\n        m_gradient = (-2/n) * sum(x * (y - y_pred))\\n        b_gradient = (-2/n) * sum(y - y_pred)\\n        m -= learning_rate * m_gradient\\n        b -= learning_rate * b_gradient\\n    return m, b\\n```\\n\\nThis code snippet demonstrates a simple implementation of gradient descent to find the optimal values of `m` and `b` in a linear regression model.')],\n",
       " 'output': 'Here is an example of gradient descent in Python:\\n\\n```python\\ndef gradient_descent(x, y, learning_rate=0.01, epochs=100):\\n    m = 0\\n    b = 0\\n    n = len(x)\\n    for _ in range(epochs):\\n        y_pred = m * x + b\\n        m_gradient = (-2/n) * sum(x * (y - y_pred))\\n        b_gradient = (-2/n) * sum(y - y_pred)\\n        m -= learning_rate * m_gradient\\n        b -= learning_rate * b_gradient\\n    return m, b\\n```\\n\\nThis code snippet demonstrates a simple implementation of gradient descent to find the optimal values of `m` and `b` in a linear regression model.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Please code an example of gradient descent for me.\",})#[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leftover Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search = DuckDuckGoSearchAPIWrapper()\n",
    "\n",
    "# search_tool = Tool(name=\"Current Search\",\n",
    "#                    func=search.run,\n",
    "#                    description=\"Useful when you need to answer questions about nouns, current events or the current state of the world.\"\n",
    "#                    )\n",
    "\n",
    "# tools = [search_tool]\n",
    "\n",
    "# memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         SystemMessage(\n",
    "#             content=\"You are a chatbot teaching assistant having a conversation with a human.\"),\n",
    "#             # The persistent system prompt\n",
    "#         MessagesPlaceholder(\n",
    "#             variable_name=\"chat_history\"),\n",
    "#             # Where the memory will be stored.\n",
    "#         HumanMessagePromptTemplate.from_template(\n",
    "#             \"{human_input}\"),\n",
    "#             # Where the human input will injected\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# llm = ChatOpenAI()\n",
    "\n",
    "# chat_llm_chain = LLMChain(\n",
    "#     llm=llm,\n",
    "#     prompt=prompt,\n",
    "#     verbose=True,\n",
    "#     memory=memory,\n",
    "# )\n",
    "\n",
    "# chat_llm_chain.predict(human_input=\"Hi there my name is August Semrau.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This defines the object that is passed between each node\n",
    "# # in the graph. We will create different nodes for each agent and tool\n",
    "# class AgentState(TypedDict):\n",
    "#     messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "#     sender: str\n",
    "\n",
    "# def agent_node(self, state, agent, name):\n",
    "#     \"\"\"Helper function to create a node for a given agent. Node that invokes agent.\"\"\"\n",
    "#     result = agent.invoke(state)\n",
    "#     # We convert the agent output into a format that is suitable to append to the global state\n",
    "#     if isinstance(result, FunctionMessage):\n",
    "#         pass\n",
    "#     else:\n",
    "#         result = HumanMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "#     return {\n",
    "#         \"messages\": [result],\n",
    "#         # Since we have a strict workflow, we can\n",
    "#         # track the sender so we know who to pass to next.\n",
    "#         \"sender\": name,\n",
    "#     }\n",
    "\n",
    "# def create_frontline_node(self, state: BaseMessage):\n",
    "#     \"\"\"Create the frontline node.\"\"\"\n",
    "#     system_message = \"\"\"You are frontline teaching assistant.\n",
    "#                     Be concise in your responses.\n",
    "#                     You can chat with students and help them with basic questions, but if the student has a teaching-related question,\n",
    "#                     do not try to answer the question directly or gather information.\n",
    "#                     Instead, immediately transfer them to the teaching agent system by asking the user to hold for a moment.\n",
    "#                     Otherwise, just respond conversationally.\"\"\"\n",
    "#     prompt = ChatPromptTemplate.from_messages([(\"system\", system_message),\n",
    "#                                                 MessagesPlaceholder(variable_name=\"messages\")])\n",
    "#     chain = prompt | self.model\n",
    "#     node = functools.partial(self.agent_node, agent=chain, name=\"Frontline\")\n",
    "#     return node\n",
    "\n",
    "# \"\"\"Teaching Agent System Graph.\"\"\"\n",
    "# graph = StateGraph(AgentState)\n",
    "\n",
    "# frontline_node = create_frontline_node()\n",
    "# graph.add_node(frontline_node)\n",
    "# graph.set_entry_point(frontline_node)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
