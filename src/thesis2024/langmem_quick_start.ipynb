{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cb_ZlAAwECnV",
    "outputId": "8aea1905-0f42-4213-aa10-13821f0e1020"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langmem.client.Client at 0x10ca55480>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thesis2024.utils import init_llm_langsmith\n",
    "from thesis2024.PMAS import LongTermMemory\n",
    "langsmith_name = \"LangMem TEST 1 \"\n",
    "llm_model = init_llm_langsmith(llm_key=3, temp=0.5, langsmith_name=langsmith_name)\n",
    "\n",
    "# from thesis2024.memory import LongTermMemory\n",
    "ltm_class = LongTermMemory(user_name=\"AugustSemrau2\")\n",
    "ltm_class.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['61b4a7d2-7585-453c-9679-9f6d7ac6be7a',\n",
       " 'b0f31285-a7fe-44f1-af0d-d4e6def0353c',\n",
       " '695877b0-798c-4fa1-905a-4075d4c90236',\n",
       " 'a8c0d86a-4ac4-466d-a2f8-b3f7663775cf',\n",
       " '5727f660-e7d2-46ad-8da0-a595279cb458',\n",
       " '139f9df0-4459-4f19-90ef-637305a8a9f3']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltm_class.past_thread_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'b51d2659-0035-44de-bd15-048b70ce4b14', 'name': 'AugustSemrau2-b51d'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltm_class.get_user_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm_class.save_conversation_step(user_query=\"Hello I am August and I study computer science at the Technical University of Denmark. I come from Jutland in Denmark. I do not understand math, and NEED to be explained technical concepts in words, not formulas.\", llm_response=\"Hello August, how can I assist you today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm_class.save_conversation_step(user_query=\"What is the height of Mount Everest?.\", llm_response=\"I will figure out.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': 'b51d2659-0035-44de-bd15-048b70ce4b14', 'memories': [{'id': '0a840bf0-fff0-4626-b3c4-73acba3c4527', 'created_at': '2024-05-13T12:22:12.388061Z', 'last_accessed': '2024-05-13T12:22:12.388061Z', 'text': 'August studies computer science', 'content': {'subject': 'August', 'predicate': 'studies', 'object': 'computer science'}, 'scores': {'recency': 1.0, 'importance': 0.6, 'relevance': 0.9725666204320412}}, {'id': '3d3fef17-7fdb-4a2f-a91f-5a1166f1f87a', 'created_at': '2024-05-13T12:22:12.388061Z', 'last_accessed': '2024-05-13T12:22:12.388061Z', 'text': 'August needs explanations in words, not formulas', 'content': {'subject': 'August', 'predicate': 'needs explanations in', 'object': 'words, not formulas'}, 'scores': {'recency': 0.574439648771844, 'importance': 1.0, 'relevance': 0.0420459489150371}}, {'id': '8325f792-3eef-4beb-a3a1-3230e82c025e', 'created_at': '2024-05-13T12:22:12.388061Z', 'last_accessed': '2024-05-13T12:22:12.388061Z', 'text': 'August studies at Technical University of Denmark', 'content': {'subject': 'August', 'predicate': 'studies at', 'object': 'Technical University of Denmark'}, 'scores': {'recency': 0.19998138843325083, 'importance': 0.4, 'relevance': 1.0}}, {'id': 'ba71c56e-2095-4c96-b735-ff6312ab586d', 'created_at': '2024-05-13T12:22:12.388061Z', 'last_accessed': '2024-05-13T12:22:12.388061Z', 'text': 'August struggles with math', 'content': {'subject': 'August', 'predicate': 'struggles with', 'object': 'math'}, 'scores': {'recency': 0.0, 'importance': 0.8, 'relevance': 0.3914595838831876}}, {'id': '87142830-41f5-410f-b573-716d8f531873', 'created_at': '2024-05-13T12:22:12.388061Z', 'last_accessed': '2024-05-13T12:22:12.388061Z', 'text': 'August comes from Jutland, Denmark', 'content': {'subject': 'August', 'predicate': 'comes from', 'object': 'Jutland, Denmark'}, 'scores': {'recency': 0.09360715107723612, 'importance': 0.0, 'relevance': 0.0}}], 'state': None, 'thread_summaries': None}\n",
      "These are the memories:\n",
      " August studies at Technical University of Denmark.\n",
      "August studies computer science.\n",
      "August struggles with math.\n",
      "August needs explanations in words, not formulas.\n",
      "August comes from Jutland, Denmark\n"
     ]
    }
   ],
   "source": [
    "memories = ltm_class.get_user_semantic_memories(query=\"What university does the user attend?\")\n",
    "memories\n",
    "print(\"These are the memories:\\n\",memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': '28f6f581-f3ac-4887-adc8-890139ce569e', 'memories': [], 'state': None, 'thread_summaries': None}\n",
      "These are the memories:\n",
      " \n"
     ]
    }
   ],
   "source": [
    "memories = ltm_class.get_user_append_memories(query=\"What university does the user attend?\")\n",
    "memories\n",
    "print(\"These are the memories:\\n\",memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'f9a97c15-b2c8-43f7-9c61-1db658173f1d', 'type': 'user_semantic_memory', 'custom_instructions': None, 'schema': {'name': 'SemanticUserMemory', 'description': 'Remember key information about the user based on the conversation.', 'parameters': {'title': 'extractTriplet', 'description': 'Extract RDF triples from the conversation.', 'type': 'object', 'properties': {'triples': {'title': 'Triples', 'description': 'The facts to extract as memories for future conversations. Be as detailed as possible, while focusing on the user information. Use names over IDs where possible.', 'type': 'array', 'items': {'$ref': '#/definitions/Triple'}}}, 'required': ['triples'], 'definitions': {'Triple': {'title': 'Triple', 'description': 'RDF triple to extract.', 'type': 'object', 'properties': {'subject': {'title': 'Subject', 'type': 'string'}, 'predicate': {'title': 'Predicate', 'type': 'string'}, 'object': {'title': 'Object', 'type': 'string'}, 'importance': {'title': 'Importance', 'description': \"Absolute importance of this memory or fact about the user,  with 1 being mundane information and 10 being poignant, identity-shaping memories about the user that you mustn't forget.\", 'minimum': 1, 'maximum': 10, 'type': 'integer'}}, 'required': ['subject', 'predicate', 'object', 'importance']}}}}, 'status': 'active', 'target_type': 'user'}\n",
      "{'id': '8c50b289-f531-4d58-8e10-a55f7e3a2322', 'type': 'user_append_state', 'custom_instructions': None, 'schema': {'name': 'CoreBelief', 'description': 'A core belief of the user.', 'parameters': {'properties': {'belief': {'default': '', 'description': 'The belief the user has about the world, themselves, or anything else.', 'title': 'Belief', 'type': 'string'}, 'why': {'default': '', 'description': 'Why the user believes this.', 'title': 'Why', 'type': 'string'}, 'context': {'default': '', 'description': 'The raw context from the conversation that leads you to conclude that the user believes this.', 'title': 'Context', 'type': 'string'}}, 'type': 'object'}}, 'status': 'active', 'target_type': 'user'}\n",
      "{'id': '7109cad1-48df-40b9-a33e-03aee766471e', 'type': 'user_append_state', 'custom_instructions': None, 'schema': {'name': 'FormativeEvent', 'description': 'Formative events for the user.', 'parameters': {'properties': {'event': {'default': '', 'description': 'The event that occurred. Must be important enough to be formative for the student.', 'title': 'Event', 'type': 'string'}, 'impact': {'default': '', 'description': 'How this event influenced the user.', 'title': 'Impact', 'type': 'string'}}, 'type': 'object'}}, 'status': 'active', 'target_type': 'user'}\n",
      "{'id': 'dcd17aa1-2541-4b3c-bd18-9998dda3480d', 'type': 'thread_summary', 'custom_instructions': None, 'schema': {'name': 'ConversationSummary', 'description': 'Summary of a conversation.', 'parameters': {'properties': {'title': {'description': 'Distinct for the conversation.', 'title': 'Title', 'type': 'string'}, 'summary': {'description': 'High level summary of the interactions.', 'title': 'Summary', 'type': 'string'}, 'topic': {'description': 'Tags for topics discussed in this conversation.', 'items': {'type': 'string'}, 'title': 'Topic', 'type': 'array'}}, 'required': ['title', 'summary', 'topic'], 'type': 'object'}}, 'status': 'active', 'target_type': 'thread'}\n",
      "{'id': '1cc9fdfb-3367-4d75-a355-a4a08d063953', 'type': 'user_state', 'custom_instructions': None, 'schema': {'name': 'UserProfile', 'description': \"A user's profile.\", 'parameters': {'properties': {'preferred_name': {'default': None, 'description': \"The user's name.\", 'title': 'Preferred Name', 'type': 'string'}, 'summary': {'default': '', 'description': 'A quick summary of how the user would describe themselves.', 'title': 'Summary', 'type': 'string'}, 'interests': {'description': 'Short (two to three word) descriptions of areas of particular interest for the user. This can be a concept, activity, or idea. Favor broad interests over specific ones.', 'items': {'type': 'string'}, 'title': 'Interests', 'type': 'array'}, 'other_info': {'description': '', 'items': {'type': 'string'}, 'title': 'Other Info', 'type': 'array'}}, 'type': 'object'}}, 'status': 'active', 'target_type': 'user'}\n"
     ]
    }
   ],
   "source": [
    "functions = ltm_class.client.list_memory_functions()\n",
    "for function in functions:\n",
    "    print(function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8c50b289-f531-4d58-8e10-a55f7e3a2322'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltm_class.belief_function[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'f3f28e9f-5d04-44ac-bcd3-ecbaa11336dc',\n",
       "  'last_message_timestamp': '2024-05-01T07:06:33.523748Z',\n",
       "  'last_message_batch_id': 0},\n",
       " {'id': '9480d479-1845-4fd5-a436-15be45a5d618',\n",
       "  'last_message_timestamp': '2024-05-11T15:03:49.490874Z',\n",
       "  'last_message_batch_id': 0},\n",
       " {'id': '1556cc40-b41e-4ac7-8143-66a61853d38c',\n",
       "  'last_message_timestamp': '2024-05-11T15:05:48.883746Z',\n",
       "  'last_message_batch_id': 0},\n",
       " {'id': '81cdd923-0a20-4e87-b4e9-63d036383651',\n",
       "  'last_message_timestamp': '2024-05-11T16:10:30.678489Z',\n",
       "  'last_message_batch_id': 1},\n",
       " {'id': '455ada55-bcc6-4676-8314-dea89c1f7aba',\n",
       "  'last_message_timestamp': '2024-05-12T16:45:12.359837Z',\n",
       "  'last_message_batch_id': 0}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltm_class.client.list_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory_function_id': 'dcd17aa1-2541-4b3c-bd18-9998dda3480d',\n",
       " 'memory_function_name': 'ConversationSummary',\n",
       " 'memory_function_type': 'thread_summary',\n",
       " 'target': '/threads/81cdd923-0a20-4e87-b4e9-63d036383651',\n",
       " 'output': {'title': \"August's Request for Assistance\",\n",
       "  'topic': ['education', 'math difficulty', 'technical explanations'],\n",
       "  'summary': 'August, a computer science student from the Technical University of Denmark, introduces himself and mentions he is from Jutland. He expresses a need for technical concepts to be explained in words rather than formulas, as he does not understand math.'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltm_class.client.list_thread_memory(thread_id=\"81cdd923-0a20-4e87-b4e9-63d036383651\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No memories for thread id 61b4a7d2-7585-453c-9679-9f6d7ac6be7a\n",
      "No memories for thread id b0f31285-a7fe-44f1-af0d-d4e6def0353c\n",
      "No memories for thread id 695877b0-798c-4fa1-905a-4075d4c90236\n",
      "No memories for thread id a8c0d86a-4ac4-466d-a2f8-b3f7663775cf\n",
      "No memories for thread id d9206843-2549-4d7e-9004-a07117f68aad\n",
      "{'5727f660-e7d2-46ad-8da0-a595279cb458': {'title': 'Introduction and Assistance Request', 'topic': ['education', 'computer science', 'learning preferences'], 'summary': 'August, a computer science student from the Technical University of Denmark, introduces themselves and mentions they come from Jutland. They express a need for explanations in technical concepts using words instead of formulas, as they do not understand math.'}, '139f9df0-4459-4f19-90ef-637305a8a9f3': {'title': 'Height Inquiry for Mount Everest', 'topic': ['Geography', 'Mountains'], 'summary': 'The user asked for the height of Mount Everest, and the AI responded that it would find out.'}}\n"
     ]
    }
   ],
   "source": [
    "ltm_class.get_thread_summaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_9tvQ3VECnR"
   },
   "source": [
    "# Intro to LangMem\n",
    "\n",
    "This is an early preview of LangMem, a longterm memory service built by LangChain designed help you eaily build personalized user experiences with LLMs. We will walk through the basic functionality as an orientation to the service, including:\n",
    "\n",
    "1. Creating memory types\n",
    "2. Posting messages to the service to trigger memory formation\n",
    "3. Recalling the memories for use in your bot.\n",
    "\n",
    "My incorporating this in your chat bot, LangMem will asynchronously help it learn their preferences and interests to improve the quality of its responses and recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ka3yBRnoECnT"
   },
   "source": [
    "## 0. Environment Setup\n",
    "\n",
    "We've created a demo 'quickstart' instance for you to try out in this notebook.\n",
    "\n",
    "While LangMem is still in private alpha, you'll need to be given access to a dedicated LangMem instance from a member LangChain team for more personal use beyond this demo. Reach out on Slack or at [support@langchain.dev](mailto:support@langchain.dev) to receive your connection information.\n",
    "\n",
    "Then you'll want to install the sdk (we will also use openai in our example chat below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aO0dD3hECnU"
   },
   "outputs": [],
   "source": [
    "%pip install -U --quiet langmem openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvDP26YNECnV"
   },
   "source": [
    "With the environment configured, you can create your client. We will connect to OpenAI and to Langmem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VKomXe8KECnV"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from langmem import AsyncClient, Client\n",
    "\n",
    "oai_client = openai.AsyncClient()\n",
    "langmem_client = AsyncClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ym7gBzdDECnX"
   },
   "source": [
    "## 1. Creating custom memory types\n",
    "\n",
    "Memory types let you model your application domain so your bot can retain inforation in a format appropriate to your use case.\n",
    "\n",
    "LangMem supports both `user` level and `thread`-level memories.\n",
    "\n",
    "LangMem supports 3 primary types of `user` memories:\n",
    "\n",
    "1. Structured \"user state\" memory to infer and manage a pre-specified user profile\n",
    "2. Structured \"user append state\" memory to infer information salient to your application context and query semantically\n",
    "3. Unstructured user semantic memory\n",
    "\n",
    "The unstructured semantic memory is enabled by default in each deployment. We will see more of that below.\n",
    "\n",
    "Enabling *structured* memory functions is as easy as posting a schema to LangMem. LangMem then automatically manages these custom profiles whenever new messages are sent to the service.\n",
    "\n",
    "### User State\n",
    "\n",
    "This is a custom user profile. Instantiate by providing a JSON schema or pydantic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pWHOBC6BECnX"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(default=None, description=\"The name of the family member.\")\n",
    "    relation: str = Field(\n",
    "        default=None, description=\"The relation of the family member to the user.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class UserProfile(BaseModel):\n",
    "    preferred_name: str = Field(default=None, description=\"The user's name.\")\n",
    "\n",
    "    summary: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"A quick summary of how the user would describe themselves.\",\n",
    "    )\n",
    "    interests: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Short (two to three word) descriptions of areas of particular interest for the user. This can be a concept, activity, or idea. Favor broad interests over specific ones.\",\n",
    "    )\n",
    "    relationships: List[Person] = Field(\n",
    "        default_factory=Person,\n",
    "        description=\"A list of friends, family members, colleagues, and other relationships.\",\n",
    "    )\n",
    "    other_info: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"\",\n",
    "    )\n",
    "\n",
    "\n",
    "user_profile_memory = await langmem_client.create_memory_function(\n",
    "    UserProfile, target_type=\"user_state\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6oyA0rkmKbt"
   },
   "source": [
    "### User Append State\n",
    "\n",
    "As the name suggests, the `user_append_state` is an append-only state (meaning the profile is never overwritten) that lets you define schema(s) to represent individual memories which you can later query semantically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v4hwI_lgmKs3"
   },
   "outputs": [],
   "source": [
    "class CoreBelief(BaseModel):\n",
    "    belief: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"The belief the user has about the world, themselves, or anything else.\",\n",
    "    )\n",
    "    why: str = Field(description=\"Why the user believes this.\")\n",
    "    context: str = Field(\n",
    "        description=\"The raw context from the conversation that leads you to conclude that the user believes this.\"\n",
    "    )\n",
    "\n",
    "\n",
    "belief_function = await langmem_client.create_memory_function(\n",
    "    CoreBelief, target_type=\"user_append_state\"\n",
    ")\n",
    "\n",
    "\n",
    "class FormativeEvent(BaseModel):\n",
    "    event: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"The event that occurred. Must be important enough to be formative for the user.\",\n",
    "    )\n",
    "    impact: str = Field(default=\"\", description=\"How this event influenced the user.\")\n",
    "\n",
    "\n",
    "event_function = await langmem_client.create_memory_function(\n",
    "    FormativeEvent, target_type=\"user_append_state\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcE-K1d9qif2"
   },
   "source": [
    "### User Semantic Memory\n",
    "\n",
    "There is also a triplet-based `user_semantic_memory` that is enabled by default. You can turn it off if you don't plan to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iOORH0BRqhMd"
   },
   "outputs": [],
   "source": [
    "functions = langmem_client.list_memory_functions(target_type=\"user\")\n",
    "semantic_memory = None\n",
    "async for func in functions:\n",
    "    if func[\"type\"] == \"user_semantic_memory\":\n",
    "        semantic_memory = func\n",
    "\n",
    "\n",
    "# Uncomment to disable the unstructured memory\n",
    "# await langmem_client.update_memory_function(semantic_memory[\"id\"], status=\"disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCCnV-QYrQbZ"
   },
   "source": [
    "### Thread Summary\n",
    "\n",
    "LangMem also supports thread-level memories. We will create them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iNscYWqDrOiq"
   },
   "outputs": [],
   "source": [
    "class ConversationSummary(BaseModel):\n",
    "    title: str = Field(description=\"Distinct for the conversation.\")\n",
    "    summary: str = Field(description=\"High level summary of the interactions.\")\n",
    "    topic: List[str] = Field(\n",
    "        description=\"Tags for topics discussed in this conversation.\"\n",
    "    )\n",
    "\n",
    "\n",
    "thread_summary_function = await langmem_client.create_memory_function(\n",
    "    ConversationSummary, target_type=\"thread_summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fm6Fkv3CECnV"
   },
   "source": [
    "## 2. Starting a conversation\n",
    "\n",
    "Memories are formed whenever your chat bot posts messages to the service.\n",
    "\n",
    "Whenever a a user ID is provided in the message metadata, LangMem will automatically create a new user entry and start tracking memories for that user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "udxkTGbeECnV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eb33e924-a2e8-473f-8dce-18e7fe03afe8 8bcec6e8-0d97-44e9-9558-8589e12dc4fb\n",
      "jimmy-5e65 johnny-a403\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "jimmy_user_id = uuid.uuid4()\n",
    "johnny_user_id = str(uuid.uuid4())\n",
    "jimmy_username = f\"jimmy-{uuid.uuid4().hex[:4]}\"\n",
    "johnny_username = f\"johnny-{uuid.uuid4().hex[:4]}\"\n",
    "\n",
    "print(jimmy_user_id, johnny_user_id)\n",
    "print(jimmy_username, johnny_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('c0f9d008-34fd-4e73-99da-640ba3738a1b')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'59a05e0c0d524d9592b0def3a2928e99'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuid.uuid4().hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8bcec6e8-0d97-44e9-9558-8589e12dc4fb'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "johnny_user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nM8xwCHAECnV"
   },
   "source": [
    "#### The following is an example conversation between 1 or more users and an AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpwP6atMECnV",
    "outputId": "612caf21-0880-4750-960e-c7a66497eb5e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'oai_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 77\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m oai_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     10\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m, messages\u001b[38;5;241m=\u001b[39mstripped_messages\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     14\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     15\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful AI assistant\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     16\u001b[0m     {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m     },\n\u001b[1;32m     75\u001b[0m ]\n\u001b[0;32m---> 77\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m completion(messages)\n\u001b[1;32m     79\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend(result\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompletion\u001b[39m(messages: \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m      6\u001b[0m     stripped_messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m         {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[1;32m      8\u001b[0m     ]\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m oai_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     10\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m, messages\u001b[38;5;241m=\u001b[39mstripped_messages\n\u001b[1;32m     11\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'oai_client' is not defined"
     ]
    }
   ],
   "source": [
    "# Unique for a given converstaion\n",
    "thread_id = uuid.uuid4()\n",
    "\n",
    "\n",
    "async def completion(messages: list):\n",
    "    stripped_messages = [\n",
    "        {k: v for k, v in m.items() if k != \"metadata\"} for m in messages\n",
    "    ]\n",
    "    return await oai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\", messages=stripped_messages\n",
    "    )\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        # Names are optional but should be consistent with a given user id, if provided\n",
    "        \"name\": jimmy_username,\n",
    "        \"content\": \"Hey johnny have i ever told you about my older bro steve?\",\n",
    "        \"metadata\": {\n",
    "            \"user_id\": str(jimmy_user_id),\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"content\": \"no, you didn't, but I think he was friends with my younger sister sueann\",\n",
    "        \"role\": \"user\",\n",
    "        \"name\": johnny_username,\n",
    "        \"metadata\": {\n",
    "            \"user_id\": str(johnny_user_id),\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"content\": \"yeah me and him used to play stickball down in the park before school started. I think it was in 1980\",\n",
    "        \"role\": \"user\",\n",
    "        \"name\": jimmy_username,\n",
    "        \"metadata\": {\n",
    "            \"user_id\": str(jimmy_user_id),\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"content\": \"That was totally 1979! I remember because i was stuck at home all summer.\",\n",
    "        \"role\": \"user\",\n",
    "        \"name\": \"Jeanne\",\n",
    "        # If the user ID isn't provided, we treat this as a guest message and won't assign memories to the user\n",
    "    },\n",
    "    {\n",
    "        \"content\": \"That was so long ago. I have gotten old and gained 200 pounds since then. I can't even remember who was president. @ai, who was the president in 1980?\",\n",
    "        \"role\": \"user\",\n",
    "        \"name\": johnny_username,\n",
    "        \"metadata\": {\n",
    "            \"user_id\": str(johnny_user_id),\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"content\": \"The president of the United States in 1980 was Jimmy Carter.\",\n",
    "        \"role\": \"assistant\",\n",
    "    },\n",
    "    {\n",
    "        \"content\": \"Wow ya i forgot that. Stickleball really impacted my life. It's how i first met Jeanne! wonder how my life would have turned out if it hadn't happened that way.\",\n",
    "        \"role\": \"user\",\n",
    "        \"name\": jimmy_username,\n",
    "        \"metadata\": {\n",
    "            \"user_id\": str(jimmy_user_id),\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"content\": \"Yeah wow. That was a big year! @ai could you remind me what else was going on that year?\",\n",
    "        \"role\": \"user\",\n",
    "        \"name\": johnny_username,\n",
    "        \"metadata\": {\n",
    "            \"user_id\": str(johnny_user_id),\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "result = await completion(messages)\n",
    "\n",
    "messages.append(result.choices[0].message)\n",
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-exSw-8ECnW"
   },
   "source": [
    "#### Now that we have the messages, we can share them with LangMem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "t2j7WVRBECnW"
   },
   "outputs": [],
   "source": [
    "await langmem_client.add_messages(thread_id=thread_id, messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "C2ItYTScECnW"
   },
   "outputs": [],
   "source": [
    "# LangMem will automatically process memories after some delay (~60 seconds), but we can eagerly process the memories as well\n",
    "await langmem_client.trigger_all_for_thread(thread_id=thread_id)\n",
    "# You could also trigger for a single user if you'd like\n",
    "# await langmem_client.trigger_all_for_user(user_id=jimmy_user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDjkX3xjECnW"
   },
   "source": [
    "#### Fetch messages\n",
    "\n",
    "You can fetch all the messages in a LangMem thread through that thread's GET endpoint. In this way, LangMem can act as a generic chat bot backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEU_DjLjECnX",
    "outputId": "99a873b8-d2da-4ff5-8dcb-438d5032364b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'You are a helpful AI assistant', 'role': 'system', 'name': None, 'metadata': {'user_id': None, 'timestamp': '2024-05-01T07:06:39.605204', 'id': '7a2dc255-deda-4b6e-a30a-c2a0076bb5f1'}}\n",
      "{'content': 'Hey johnny have i ever told you about my older bro steve?', 'role': 'user', 'name': 'jimmy-ff52', 'metadata': {'user_id': 'dd848449-c7af-4a75-85a5-e62124afd918', 'timestamp': '2024-05-01T07:06:39.605233', 'id': '6b5586aa-bf66-48f3-8c54-89484cd1c5b0'}}\n",
      "{'content': \"no, you didn't, but I think he was friends with my younger sister sueann\", 'role': 'user', 'name': 'johnny-7b61', 'metadata': {'user_id': '4e15d045-7d1b-4be3-af0a-905d07c264fc', 'timestamp': '2024-05-01T07:06:39.605252', 'id': 'fee65f5a-54f9-467d-b4c0-ed4776b5fc7b'}}\n",
      "{'content': 'yeah me and him used to play stickball down in the park before school started. I think it was in 1980', 'role': 'user', 'name': 'jimmy-ff52', 'metadata': {'user_id': 'dd848449-c7af-4a75-85a5-e62124afd918', 'timestamp': '2024-05-01T07:06:39.605270', 'id': '1f283cc6-ea89-4dcf-b30d-058d492f4e87'}}\n",
      "{'content': 'That was totally 1979! I remember because i was stuck at home all summer.', 'role': 'user', 'name': None, 'metadata': {'user_id': None, 'timestamp': '2024-05-01T07:06:39.605288', 'id': '5f709010-fad8-4f90-a766-edd34dfb4ce2'}}\n",
      "{'content': \"That was so long ago. I have gotten old and gained 200 pounds since then. I can't even remember who was president. @ai, who was the president in 1980?\", 'role': 'user', 'name': 'johnny-7b61', 'metadata': {'user_id': '4e15d045-7d1b-4be3-af0a-905d07c264fc', 'timestamp': '2024-05-01T07:06:39.605306', 'id': '49791b7b-73dc-40ba-a368-a0e8e2557f74'}}\n",
      "{'content': 'The president of the United States in 1980 was Jimmy Carter.', 'role': 'assistant', 'name': None, 'metadata': {'user_id': None, 'timestamp': '2024-05-01T07:06:39.605323', 'id': '90926326-7ec1-43d1-a77f-9494e595f5e9'}}\n",
      "{'content': \"Wow ya i forgot that. Stickleball really impacted my life. It's how i first met Jeanne! wonder how my life would have turned out if it hadn't happened that way.\", 'role': 'user', 'name': 'jimmy-ff52', 'metadata': {'user_id': 'dd848449-c7af-4a75-85a5-e62124afd918', 'timestamp': '2024-05-01T07:06:39.605339', 'id': 'ac54bf93-3462-4594-96f1-ea0768526d85'}}\n",
      "{'content': 'Yeah wow. That was a big year! @ai could you remind me what else was going on that year?', 'role': 'user', 'name': 'johnny-7b61', 'metadata': {'user_id': '4e15d045-7d1b-4be3-af0a-905d07c264fc', 'timestamp': '2024-05-01T07:06:39.605356', 'id': 'f01fe28c-e6e8-4f12-9835-6ce348b61f79'}}\n",
      "{'content': 'In 1980, some notable events included the eruption of Mount St. Helens in May, the beginning of the Iran-Iraq War, the launch of CNN (Cable News Network), and the release of the film \"The Empire Strikes Back.\" Additionally, the United States boycotted the Summer Olympics in Moscow in response to the Soviet invasion of Afghanistan.', 'role': 'assistant', 'name': None, 'metadata': {'user_id': None, 'timestamp': '2024-05-01T07:06:39.605373', 'id': 'da850ce0-2be7-4d30-a281-ace5d70056c7'}}\n"
     ]
    }
   ],
   "source": [
    "messages = langmem_client.list_messages(thread_id=thread_id)\n",
    "async for message in messages:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6HKQyRwECnX"
   },
   "source": [
    "### 3. Query Memory\n",
    "\n",
    "You can also query the user memory, once it's updated. This may take a few moments - please be patient ðŸ˜Š\n",
    "\n",
    "To query the unstructured semantic memory, you can provide query text and the number of memories to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pUyGysfECnX",
    "outputId": "18d5b2a3-04be-4b36-878b-e28f6878bd2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'a5e9850c-49df-4d23-8d70-0487e4970e0f',\n",
       "  'created_at': '2024-05-01T07:06:52.160163Z',\n",
       "  'last_accessed': '2024-05-01T07:06:52.160163Z',\n",
       "  'text': 'User met spouse Jeanne through stickball',\n",
       "  'content': {'subject': 'User',\n",
       "   'predicate': 'met spouse',\n",
       "   'object': 'Jeanne through stickball'},\n",
       "  'scores': {'recency': 0.9998792089578877,\n",
       "   'importance': 1.0,\n",
       "   'relevance': 0.759507087793172}},\n",
       " {'id': '705c475b-6f89-4f88-ae67-11d50f22913c',\n",
       "  'created_at': '2024-05-01T07:06:52.160163Z',\n",
       "  'last_accessed': '2024-05-01T07:06:52.160163Z',\n",
       "  'text': 'User reflects on impact of stickball on life',\n",
       "  'content': {'subject': 'User',\n",
       "   'predicate': 'reflects on impact of stickball',\n",
       "   'object': 'on life'},\n",
       "  'scores': {'recency': 0.9999455432159969,\n",
       "   'importance': 0.75,\n",
       "   'relevance': 1.0}},\n",
       " {'id': 'e7d8357f-81ec-49ec-9508-2485c87f13d1',\n",
       "  'created_at': '2024-05-01T07:06:52.160163Z',\n",
       "  'last_accessed': '2024-05-01T07:06:52.160163Z',\n",
       "  'text': 'User played stickball with Steve in the park before school in 1979',\n",
       "  'content': {'subject': 'User',\n",
       "   'predicate': 'played stickball with Steve',\n",
       "   'object': 'in the park before school in 1979'},\n",
       "  'scores': {'recency': 0.9998227787991115,\n",
       "   'importance': 0.75,\n",
       "   'relevance': 0.9141351268321}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait a few moments for the memories to process. If this is empty, you'll likely have to wait a bit longer\n",
    "mems = None\n",
    "while not mems:\n",
    "    mem_response = await langmem_client.query_user_memory(\n",
    "        user_id=jimmy_user_id, text=\"stickleball\", k=3\n",
    "    )\n",
    "    mems = mem_response[\"memories\"]\n",
    "mems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-LcRJjS88oZc",
    "outputId": "54301291-6746-4e6b-a14a-ec4ba2bcbf26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': 'dd848449-c7af-4a75-85a5-e62124afd918',\n",
       " 'memories': [{'id': '6c169ccf-ad73-4315-afbc-ca7edf633383',\n",
       "   'created_at': '2024-05-01T07:06:43.560156Z',\n",
       "   'last_accessed': '2024-05-01T07:06:43.560156Z',\n",
       "   'text': '',\n",
       "   'content': {'belief': 'Playing stickball in the park before school in 1980 was a significant part of my childhood.',\n",
       "    'why': 'The user reminisces about playing stickball with their older brother Steve in the park before school started around 1980, indicating it was a memorable and impactful part of their childhood.',\n",
       "    'context': 'yeah me and him used to play stickball down in the park before school started. I think it was in 1980'},\n",
       "   'scores': {'recency': 1.0, 'importance': 0.5, 'relevance': 1.0}},\n",
       "  {'id': '3a302a48-7230-4bf8-9265-89a1936e692a',\n",
       "   'created_at': '2024-05-01T07:06:43.278278Z',\n",
       "   'last_accessed': '2024-05-01T07:06:43.278278Z',\n",
       "   'text': '',\n",
       "   'content': {'event': 'Playing stickball in the park before school in 1980',\n",
       "    'impact': 'This activity was significant for the user as it was how they first met Jeanne, suggesting it had a meaningful impact on their life.'},\n",
       "   'scores': {'recency': 0.0, 'importance': 0.5, 'relevance': 0.0}}],\n",
       " 'state': None,\n",
       " 'thread_summaries': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In a similar way, you can include\n",
    "# different `user_append_state` memory results\n",
    "# in the ranked response\n",
    "mems = await langmem_client.query_user_memory(\n",
    "    user_id=jimmy_user_id,\n",
    "    text=\"stickleball\",\n",
    "    k=3,\n",
    "    memory_function_ids=[belief_function[\"id\"], event_function[\"id\"]],\n",
    ")\n",
    "mems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYUpaZuZECnX",
    "outputId": "68029b1c-b8ff-4554-e69d-0cd9de4a161e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': None,\n",
       " 'interests': None,\n",
       " 'other_info': ['Played stickball in the park before school around 1979/1980',\n",
       "  'Meeting Jeanne during stickball significantly impacted his life'],\n",
       " 'relationships': [{'name': 'Steve', 'relation': 'older brother'}],\n",
       " 'preferred_name': 'Johnny'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For user state (profile) memories, you can make a faster and simple get request\n",
    "user_state = None\n",
    "while not user_state:\n",
    "    user_state = await langmem_client.get_user_memory(\n",
    "        user_id=jimmy_user_id, memory_function_id=user_profile_memory[\"id\"]\n",
    "    )\n",
    "user_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSoB0kvw9wy-",
    "outputId": "04850e4b-955b-4a89-a8fa-01649f182ce4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'memory_function_id': '21f51836-cd0d-4b2d-b93b-3002df113b2a',\n",
       "  'memory_function_name': 'ConversationSummary',\n",
       "  'memory_function_type': 'thread_summary',\n",
       "  'target': '/threads/f3f28e9f-5d04-44ac-bcd3-ecbaa11336dc',\n",
       "  'output': {'title': 'Reminiscing About the Past',\n",
       "   'topic': ['Personal Memories', '1980 Events', 'Presidential History'],\n",
       "   'summary': \"The conversation involves two users reminiscing about their past, specifically around the year 1980. One user mentions playing stickball with their older brother Steve, which was a significant memory for them as it was how they first met Jeanne. They also discuss notable events from 1980, such as the eruption of Mount St. Helens, the Iran-Iraq War, the launch of CNN, and the release of 'The Empire Strikes Back.' The AI provides factual information, including that Jimmy Carter was the president in 1980 and details about other significant events from that year.\"}}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can list all the thread summary memories for a given thread as well!\n",
    "await langmem_client.list_thread_memory(thread_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NwfHsi3ECnX"
   },
   "source": [
    "## 4. Use in a later conversations\n",
    "\n",
    "As you can see, we've extracted some useful information from the previous conversation. We imagine you would fetch these facts in later conversations to provide your bot with additional helpful context about the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8yy5hYNECnX",
    "outputId": "0e41f638-fa6e-4602-b40c-5101d3ffdcb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your older brother's name is Steve.\n"
     ]
    }
   ],
   "source": [
    "async def completion_with_memory(messages: list, user_id: uuid.UUID):\n",
    "    memories = await langmem_client.query_user_memory(\n",
    "        user_id=user_id, text=messages[-1][\"content\"], k=3\n",
    "    )\n",
    "    facts = \"\\n\".join([mem[\"text\"] for mem in memories[\"memories\"]])\n",
    "    system_prompt = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"You are a helpful assistant. You know the following facts about the user with which you are conversing.\\n\\n{facts}\",\n",
    "    }\n",
    "    return await completion([system_prompt] + messages)\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"name\": jimmy_username,\n",
    "        \"content\": \"Hi there! I'm curious what you remember. What's my brother's name?\",\n",
    "        \"metadata\": {\"user_id\": jimmy_user_id},\n",
    "    }\n",
    "]\n",
    "res = await completion_with_memory(messages, user_id=jimmy_user_id)\n",
    "print(res.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AX4g98PECnY"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this walkthrough, you saved memories for two users to track their interests and other attributes. You did so simply by sending your chat messages to the LangMem service. You then automatically triggered updates to store long-term memories of three forms:\n",
    "\n",
    "1. User state \"profiles\", which follow your custom schema\n",
    "2. User append state, which store atomic memories following your custom schema and can be queried semantically.\n",
    "3. General-purpose knowledge as semantic triplets\n",
    "\n",
    "\n",
    "You also tracked thread-scoped summary memories to help you organize your conversational threads.\n",
    "\n",
    "Finally, let's clean up our work! This demo is a shared workspace :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "p4I1sDJNEWKM"
   },
   "outputs": [],
   "source": [
    "## Cleanup\n",
    "\n",
    "functions = langmem_client.list_memory_functions()\n",
    "\n",
    "async for func in functions:\n",
    "    if func[\"type\"] == \"user_semantic_memory\":\n",
    "        continue\n",
    "    await langmem_client.delete_memory_function(func[\"id\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
