{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to tokenize a book in my library, and then spit out key metrics like token count, unique token count, and token frequency.\n",
    "# Use the following code as inspiration\n",
    "\n",
    "\"\"\"Create the dataset for the thesis.\n",
    "\n",
    "Making the dataset for the thesis, by loading datasources (currently PDFs)\n",
    "and creating a persistent Chroma vector store from them.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38230196758079316"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = f'../data/raw/DL_IanGoodfellow'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Process each PDF file in the directory\n",
    "all_docs = []\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.pdf'):\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "\n",
    "        # Load PDF document\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        documents = loader.load()\n",
    "\n",
    "        # Split documents into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=4,\n",
    "            chunk_overlap=0,\n",
    "            separators=[\"\\n\\n\", \"\\n\", r\"(?<=\\. )\", \" \", \"\"]\n",
    "        )\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        print(f\"{len(docs)} chunks created from {filename}\")\n",
    "\n",
    "        num_tokens = num_tokens_from_string(str(documents), \"cl100k_base\")\n",
    "        print(f\"Number of tokens: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 217\n"
     ]
    }
   ],
   "source": [
    "string1 = \"\"\"Teaching Assistant is a large language model trained by OpenAI.\n",
    "\n",
    "Teaching Assistant is designed to be able to assist with teaching related tasks, from answering simple questions to providing in-depth explanations and discussions on STEM topics. \n",
    "\n",
    "As a language model, Teaching Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "\n",
    "Teaching Assistant is constantly learning and improving, and its capabilities are constantly evolving. \n",
    "\n",
    "It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. \n",
    "\n",
    "Additionally, Teaching Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
    "\n",
    "Overall, Teaching Assistant is a powerful tool that can help students with understanding STEM topics. \n",
    "\n",
    "Whether you need help with a specific question or just want to have a conversation about a particular topic, Teaching Assistant is here to assist.\"\"\"\n",
    "\n",
    "\n",
    "num_tokens = num_tokens_from_string(string1, \"cl100k_base\")\n",
    "print(f\"Number of tokens: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
